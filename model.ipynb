{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1122d1a7",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "---\n",
    "\n",
    "For my evaluation metric, I will use accuracy. I want to minimize both false positives and false negatives. I think it would be worse to apply to a fraudulent job listing because whoever posted it could potentially access sensitive personal information. However, I also do not want to miss out on potential job opportunities by not applying to a job listing that was classified as fraudulent when it was really authentic.\n",
    "\n",
    "For my baseline, I will predict that every job listing is authentic since the majority of the listings in this dataset are actually authentic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d77f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wrangle as w\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832fb628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9818, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = w.split_data(w.wrangle_jobs(), 'fraudulent')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2453d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y versions of train, validate, and test samples\n",
    "x_train = train.drop(columns=['fraudulent', 'continent', 'employment_type', 'required_education', 'required_experience'])\n",
    "y_train = train.fraudulent\n",
    "\n",
    "x_validate = validate.drop(columns=['fraudulent', 'continent', 'employment_type', 'required_education', 'required_experience'])\n",
    "y_validate = validate.fraudulent\n",
    "\n",
    "x_test = test.drop(columns=['fraudulent', 'continent', 'employment_type', 'required_education', 'required_experience'])\n",
    "y_test = test.fraudulent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0afec",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04c842b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy on Train: 95.16%\n",
      "Baseline Accuracy on Validate: 95.18%\n"
     ]
    }
   ],
   "source": [
    "# compute baseline accuracy\n",
    "print(f'Baseline Accuracy on Train: {(y_train == 0).mean():.2%}')\n",
    "print(f'Baseline Accuracy on Validate: {(y_validate == 0).mean():.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5f7c1",
   "metadata": {},
   "source": [
    "## Model 1: Decision Tree\n",
    "For this model, I will be using all of the features in my dataframe, a max depth of 3, and I will set the random state to 123 for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea333f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Train Accuracy: 95.16%\n",
      "Model 1 Validate Accuracy: 95.18%\n"
     ]
    }
   ],
   "source": [
    "# create decision tree object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "# fit object to train\n",
    "clf = clf.fit(x_train, y_train)\n",
    "# make predictions\n",
    "y_pred1 = clf.predict(x_train)\n",
    "y_pred_v1 = clf.predict(x_validate)\n",
    "# compute and print accuracy\n",
    "print(f'Model 1 Train Accuracy: {accuracy_score(y_train, y_pred1):.2%}')\n",
    "print(f'Model 1 Validate Accuracy: {accuracy_score(y_validate, y_pred_v1):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168f068",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest\n",
    "For this model, I will be using all of the features in my dataframe. I will set minimum samples per leaf to 1 and max depth to 10. I will also set a random state (123) so my work can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b8f79c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Train Accuracy: 95.44%\n",
      "Model 2 Validate Accuracy: 95.58%\n"
     ]
    }
   ],
   "source": [
    "# create random forest object\n",
    "rf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "# fit object to train sample\n",
    "rf.fit(x_train, y_train)\n",
    "# make predictions\n",
    "y_pred2 = rf.predict(x_train)\n",
    "y_pred_v2 = rf.predict(x_validate)\n",
    "# compute and print accuracy\n",
    "print(f'Model 2 Train Accuracy: {accuracy_score(y_train, y_pred2):.2%}')\n",
    "print(f'Model 2 Validate Accuracy: {accuracy_score(y_validate, y_pred_v2):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea4d54",
   "metadata": {},
   "source": [
    "## Model 3: Random Forest\n",
    "For this model, I will only be using the features that started off as int dtypes. I will leave the hyperparameters the same as in Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03a9b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Train Accuracy: 95.16%\n",
      "Model 3 Validate Accuracy: 95.18%\n"
     ]
    }
   ],
   "source": [
    "# create random forest object\n",
    "rf2 = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "# fit object to train sample\n",
    "rf2.fit(x_train[['telecommuting', 'has_company_logo', 'has_questions']], y_train)\n",
    "# make predictions\n",
    "y_pred3 = rf2.predict(x_train[['telecommuting', 'has_company_logo', 'has_questions']])\n",
    "y_pred_v3 = rf2.predict(x_validate[['telecommuting', 'has_company_logo', 'has_questions']])\n",
    "# compute and print accuracy\n",
    "print(f'Model 3 Train Accuracy: {accuracy_score(y_train, y_pred3):.2%}')\n",
    "print(f'Model 3 Validate Accuracy: {accuracy_score(y_validate, y_pred_v3):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d0541d",
   "metadata": {},
   "source": [
    "My best model is Model 2. It has an accuracy of 95.44% on train and 95.58% on validate. Both of these beat the baseline! Next, I will run this model on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "219c39fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Test Accuracy: 95.32%\n"
     ]
    }
   ],
   "source": [
    "# create random forest object\n",
    "rf = RandomForestClassifier(min_samples_leaf=1, max_depth=10, random_state=123)\n",
    "# fit object to train sample\n",
    "rf.fit(x_train, y_train)\n",
    "# make predictions\n",
    "y_pred_t2 = rf.predict(x_test)\n",
    "# compute and print accuracy\n",
    "print(f'Model 2 Test Accuracy: {accuracy_score(y_test, y_pred_t2):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2de3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
